{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5b55df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mauriga                 \u001b[m  Thu Dec 15 16:55:54 2022  \u001b[1m\u001b[30m510.47.03\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla V100-SXM2-32GB\u001b[m |\u001b[31m 38'C\u001b[m, \u001b[32m 22 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6627\u001b[m / \u001b[33m32768\u001b[m MB | \u001b[1m\u001b[30me.trofimenko\u001b[m(\u001b[33m6367M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTesla V100-SXM2-32GB\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  260\u001b[m / \u001b[33m32768\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTesla V100-SXM2-32GB\u001b[m |\u001b[31m 33'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  260\u001b[m / \u001b[33m32768\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTesla V100-SXM2-32GB\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  260\u001b[m / \u001b[33m32768\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8daae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0+cu117'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f85770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from jiwer import wer, cer\n",
    "\n",
    "import glob\n",
    "import subprocess\n",
    "import tarfile\n",
    "import wget\n",
    "import copy\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.parts.preprocessing import perturb, segment\n",
    "from nemo.collections.asr.metrics.wer import word_error_rate\n",
    "from nemo.utils import logging, exp_manager\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as ptl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016a27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manifest(path):\n",
    "    manifest = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            data = json.loads(line)\n",
    "            manifest.append(data)\n",
    "    return manifest\n",
    "\n",
    "data_dir = 'datasets/'\n",
    "\n",
    "LANGUAGE = \"ru\"\n",
    "\n",
    "manifest_dir = os.path.join('manifests', LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b72adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_manifests = f'{manifest_dir}/commonvoice_train_manifest_lower.json,'    \n",
    "train_manifests += f'{manifest_dir}/commonvoice_dev_manifest_lower.json,'    \n",
    "train_manifests += f'{manifest_dir}/commonvoice4_train_manifest_lower.json,'   \n",
    "train_manifests += f'{manifest_dir}/commonvoice4_dev_manifest_lower.json,'    \n",
    "train_manifests += f'{manifest_dir}/commonvoice5_train_manifest_lower.json,'  \n",
    "train_manifests += f'{manifest_dir}/commonvoice5_dev_manifest_lower.json,'     \n",
    "train_manifests += f'{manifest_dir}/commonvoice9_train_manifest_lower.json,' \n",
    "train_manifests += f'{manifest_dir}/commonvoice9_dev_manifest_lower.json,'     \n",
    "train_manifests += f'{manifest_dir}/commonvoice10_train_manifest_lower.json,' \n",
    "train_manifests += f'{manifest_dir}/commonvoice10_dev_manifest_lower.json,'      \n",
    "train_manifests += f'{manifest_dir}/commonvoice11_train_manifest_lower.json,'  \n",
    "train_manifests += f'{manifest_dir}/commonvoice11_dev_manifest_lower.json,'    \n",
    "# train_manifests += f'golos/train/manifest.json,'                         \n",
    "train_manifests += f'ruls/train/train_manifest_lower.json,'                    \n",
    "train_manifests += f'ruls/dev/dev_manifest_lower.json'                        \n",
    "\n",
    "valid_manifests = f'{manifest_dir}/commonvoice_test_manifest_lower.json,'    \n",
    "valid_manifests += f'{manifest_dir}/commonvoice4_test_manifest_lower.json,'  \n",
    "valid_manifests += f'{manifest_dir}/commonvoice5_test_manifest_lower.json,'   \n",
    "valid_manifests += f'{manifest_dir}/commonvoice9_test_manifest_lower.json,'    \n",
    "valid_manifests += f'{manifest_dir}/commonvoice10_test_manifest_lower.json,'   \n",
    "valid_manifests += f'{manifest_dir}/commonvoice11_test_manifest_lower.json,'   \n",
    "# valid_manifests += f'golos/test/crowd/manifest.json,'                    \n",
    "# valid_manifests += f'golos/test/farfield/manifest.json,'                 \n",
    "valid_manifests += f'ruls/test/test_manifest_lower.json' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3fd6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model, train_manifest_dir, valid_manifest_dir, \n",
    "               train_batch_size, valid_batch_size, learning_rate):\n",
    "    \n",
    "    cfg = copy.deepcopy(model.cfg)\n",
    "    \n",
    "    audio_augmentations = dict(\n",
    "    white_noise = dict(\n",
    "        prob=0.5,\n",
    "        min_level=-90,\n",
    "        max_level=-46\n",
    "    ),\n",
    "    gain = dict(\n",
    "        prob=0.5,\n",
    "        min_gain_dbfs=0,\n",
    "        max_gain_dbfs=50\n",
    "    ))\n",
    "\n",
    "    with open_dict(cfg):    \n",
    "        ## TRAIN CONFIG ##\n",
    "        cfg.train_ds.manifest_filepath = train_manifest_dir\n",
    "        cfg.train_ds.normalize_transcripts = False\n",
    "        cfg.train_ds.batch_size = train_batch_size\n",
    "        cfg.train_ds.num_workers = 32\n",
    "        cfg.train_ds.pin_memory = True\n",
    "        cfg.train_ds.trim_silence = True\n",
    "        cfg.train_ds.sample_rate = 16000\n",
    "        cfg.train_ds.augmentor = audio_augmentations\n",
    "\n",
    "        ## VALID CONFIG ##\n",
    "        cfg.validation_ds.manifest_filepath = valid_manifest_dir\n",
    "        cfg.validation_ds.normalize_transcripts = False\n",
    "        cfg.validation_ds.batch_size = valid_batch_size\n",
    "        cfg.validation_ds.num_workers = 32\n",
    "        cfg.validation_ds.pin_memory = True\n",
    "        cfg.validation_ds.trim_silence = True\n",
    "        cfg.validation_ds.sample_rate = 16000\n",
    "\n",
    "    # setup data loaders with new configs\n",
    "    model.setup_training_data(cfg.train_ds)\n",
    "    model.setup_multiple_validation_data(cfg.validation_ds)\n",
    "\n",
    "    ## OPTIMIZERS ##\n",
    "    with open_dict(model.cfg.optim):\n",
    "        model.cfg.optim.name = 'novograd'\n",
    "        model.cfg.optim.lr = learning_rate\n",
    "        model.cfg.optim.betas = [0.8, 0.5]  \n",
    "        model.cfg.optim.weight_decay = 0.001  \n",
    "        model.cfg.optim.sched.name = 'CosineAnnealing'\n",
    "        model.cfg.optim.sched.warmup_steps = None  \n",
    "        model.cfg.optim.sched.warmup_ratio = None\n",
    "        model.cfg.optim.sched.min_lr = 0.0\n",
    "        model.cfg.optim.sched.last_epoch = -1\n",
    "            \n",
    "    ## AUGMENATION ##\n",
    "    with open_dict(model.cfg.spec_augment):\n",
    "#         model.cfg.spec_augment.freq_masks = 2\n",
    "#         model.cfg.spec_augment.freq_width = 25\n",
    "#         model.cfg.spec_augment.time_masks = 2\n",
    "#         model.cfg.spec_augment.time_width = 0.05\n",
    "        \n",
    "        model.cfg.spec_augment.rect_freq = 50\n",
    "        model.cfg.spec_augment.rect_masks = 5\n",
    "        model.cfg.spec_augment.rect_time = 120\n",
    "\n",
    "    model.spec_augmentation = model.from_config_dict(model.cfg.spec_augment)\n",
    "\n",
    "    model._wer.use_cer = False\n",
    "\n",
    "    model._wer.log_prediction = False\n",
    "\n",
    "def init_trainer(model, num_epochs: int, log_every_n_steps: int, val_every_n_epoch: int,\n",
    "                 name_of_run: str, name_of_project: str, model_name: str):\n",
    "\n",
    "    trainer = ptl.Trainer(devices=1, \n",
    "                          accelerator='gpu', \n",
    "                          auto_select_gpus=True,\n",
    "                          strategy=None,\n",
    "                          max_epochs=num_epochs, \n",
    "                          auto_lr_find=False,\n",
    "                          accumulate_grad_batches=1,\n",
    "                          enable_checkpointing=False,\n",
    "                          logger=False,\n",
    "                          log_every_n_steps=log_every_n_steps,\n",
    "                          check_val_every_n_epoch=val_every_n_epoch)\n",
    "\n",
    "    model.set_trainer(trainer)\n",
    "    model.cfg = model._cfg\n",
    "\n",
    "    # Environment variable generally used for multi-node multi-gpu training.\n",
    "    # In notebook environments, this flag is unnecessary and can cause logs of multiple training runs to overwrite each other.\n",
    "    os.environ.pop('NEMO_EXPM_VERSION', None)\n",
    "\n",
    "    config = exp_manager.ExpManagerConfig(\n",
    "        exp_dir=f'experiments/',\n",
    "        name=f\"ASR-{model_name}-Model-{LANGUAGE}\",\n",
    "        checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "                               monitor=\"val_wer\",\n",
    "                               mode=\"min\",\n",
    "                               always_save_nemo=True,\n",
    "                               save_best_model=True),\n",
    "        create_wandb_logger = True, \n",
    "        wandb_logger_kwargs = {'name': name_of_run,\n",
    "                               'project': name_of_project, \n",
    "                               'log_model': 'all'})\n",
    "\n",
    "    config = OmegaConf.structured(config)\n",
    "    logdir = exp_manager.exp_manager(trainer, config)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0efef894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-02 14:15:35 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: manifests/ru/commonvoice_train_manifest_lower.json,manifests/ru/commonvoice_dev_manifest_lower.json,manifests/ru/commonvoice4_train_manifest_lower.json,manifests/ru/commonvoice4_dev_manifest_lower.json,manifests/ru/commonvoice5_train_manifest_lower.json,manifests/ru/commonvoice5_dev_manifest_lower.json,manifests/ru/commonvoice9_train_manifest_lower.json,manifests/ru/commonvoice9_dev_manifest_lower.json,manifests/ru/commonvoice10_train_manifest_lower.json,manifests/ru/commonvoice10_dev_manifest_lower.json,manifests/ru/commonvoice11_train_manifest_lower.json,manifests/ru/commonvoice11_dev_manifest_lower.json,ruls/train/train_manifest_lower.json,ruls/dev/dev_manifest_lower.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 44\n",
      "    trim_silence: true\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 32\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    parser: ru\n",
      "    normalize_transcripts: false\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-12-02 14:15:35 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: manifests/ru/commonvoice_test_manifest_lower.json,manifests/ru/commonvoice4_test_manifest_lower.json,manifests/ru/commonvoice5_test_manifest_lower.json,manifests/ru/commonvoice9_test_manifest_lower.json,manifests/ru/commonvoice10_test_manifest_lower.json,manifests/ru/commonvoice11_test_manifest_lower.json,ruls/test/test_manifest_lower.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 44\n",
      "    num_workers: 32\n",
      "    shuffle: false\n",
      "    parser: ru\n",
      "    normalize_transcripts: false\n",
      "    pin_memory: true\n",
      "    trim_silence: true\n",
      "    \n",
      "[NeMo W 2022-12-02 14:15:35 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: test/mcv/test_ru.jsonl\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    parser: ru\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-02 14:15:35 features:225] PADDING: 16\n",
      "[NeMo I 2022-12-02 14:15:36 save_restore_connector:243] Model EncDecCTCModel was successfully restored from /home/projects/asr/ASR_models/golos_ft_withSpecAug_50epochs.nemo.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'ASR_models/golos_ft_withSpecAug_50epochs.nemo'\n",
    "model = nemo.collections.asr.models.EncDecCTCModel.restore_from(model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc5edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-02 14:15:55 collections:194] Dataset loaded with 211672 files totalling 327.46 hours\n",
      "[NeMo I 2022-12-02 14:15:55 collections:195] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2022-12-02 14:15:59 collections:194] Dataset loaded with 51543 files totalling 83.88 hours\n",
      "[NeMo I 2022-12-02 14:15:59 collections:195] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "init_model(model = model, \n",
    "           train_manifest_dir = train_manifests,\n",
    "           valid_manifest_dir = valid_manifests, \n",
    "           train_batch_size = 32, valid_batch_size = 32, \n",
    "           learning_rate = 0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "533e2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-02 14:16:36 exp_manager:291] Experiments will be logged at experiments/ASR-Golos-Model-ru/2022-12-02_14-16-36\n",
      "[NeMo I 2022-12-02 14:16:36 exp_manager:669] TensorboardLogger has been set up\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>experiments/wandb/run-20221202_141636-2022-12-02_14-16-36</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/abletobetable_ipavlov/asr_experiments/runs/2022-12-02_14-16-36\" target=\"_blank\">golos_ft50e_withAudAug</a></strong> to <a href=\"https://wandb.ai/abletobetable_ipavlov/asr_experiments\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-02 14:16:42 exp_manager:684] WandBLogger has been set up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-02 14:16:42 nemo_logging:349] /home/a.lokis/miniconda3/envs/asr_env/lib/python3.9/site-packages/pytorch_lightning/loggers/logger.py:229: LightningDeprecationWarning: `LoggerCollection` is deprecated in v1.6 and will be removed in v1.8. Directly pass a list of loggers to the Trainer and access the list via the `trainer.loggers` attribute.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-12-02 14:16:42 nemo_logging:349] /home/a.lokis/miniconda3/envs/asr_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:2274: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
      "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
      "    \n",
      "[NeMo W 2022-12-02 14:16:42 exp_manager:919] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 5 epochs to ensure that checkpointing will not error out.\n"
     ]
    }
   ],
   "source": [
    "trainer = init_trainer(model=model, num_epochs=50, \n",
    "                       log_every_n_steps=200, val_every_n_epoch=5, \n",
    "                       name_of_run='golos_ft50e_withAudAug', \n",
    "                       name_of_project='asr_experiments', \n",
    "                       model_name='Golos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf0ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-02 14:16:47 modelPT:597] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.8, 0.5]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.0003\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2022-12-02 14:16:47 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7fca30523460>\" \n",
      "    will be used during training (effective maximum steps = 330750) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: null\n",
      "    min_lr: 0.0\n",
      "    last_epoch: -1\n",
      "    max_steps: 330750\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConvASREncoder                    | 18.9 M\n",
      "2 | decoder           | ConvASRDecoder                    | 34.9 K\n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | _wer              | WER                               | 0     \n",
      "------------------------------------------------------------------------\n",
      "18.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 M    Total params\n",
      "75.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa3c23f0a7649d0a7172e74e8405aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3f8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
